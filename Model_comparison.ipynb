{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_comparison",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPLcuw0gvh/3sYf6HVKawl1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RozitaAbdoli/credit_default_mining/blob/main/Model_comparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8Yn7UbfnkRP"
      },
      "source": [
        "### Comparing the performance of multiple ML algorithms\n",
        "In this notebook, the performance of several ML algorithms including ensemble learners will be compared. The ensemble learners are Random Forest, Adaptive Boost, and Gradient Boost Algorithms that use Decision Trees as weak learners. They:  \n",
        "\n",
        "* Are non-parametric and don't require data to be normally distributed.\n",
        "* Can handle both numeric and categorical data types, and categorical predictors don't have to be one-hot encoded.\n",
        "* The correlation between predictors does not affect the performance of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BSSZUNhs9KQ"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from imblearn.combine import SMOTETomek \n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "# from sklearn.neural_network import MLPClassifier\n",
        "# from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, roc_curve, roc_auc_score, f1_score"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZqXZKNNtKWT",
        "outputId": "6d3e7edb-6c9e-4306-eccb-0952cb0d10ba"
      },
      "source": [
        "#Import Drive API and authenticate\n",
        "from google.colab import drive\n",
        "#Mount Drive to the Colab VM\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWZHZozJuZW_"
      },
      "source": [
        "#Load the dataset into pandas DataFrame\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Capstone_project/v2_credit_default.csv\")"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kkD5ioWL-QE"
      },
      "source": [
        "# #  Selected features Based on Pearson and Spearman's rank correlations with the dependent variable, and XGBoost feature importance rankings:\n",
        "# df = df[['AGE', 'LIMIT_BAL', 'Pay_Apr', 'Repay_Sept', 'Pay_Sept','Default' ]]"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLrZFqzQQ_ZF",
        "outputId": "7755b682-11a8-4822-8908-42c2782ebe3c"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29965, 24)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9mHWG7JtZVD"
      },
      "source": [
        "#Seperate the independent and dependent variables.\n",
        "df_independent = df.drop(['Default'], axis=1)\n",
        "df_default = df['Default']"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47RdMkt6tdi6"
      },
      "source": [
        "# split the data into 75% training+validation and 25% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_independent, df_default, test_size=0.25, random_state=1) "
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5QJjWPXFPaB"
      },
      "source": [
        "# Scale X_train and X_test.\n",
        "X_train_scaled = preprocessing.MinMaxScaler().fit_transform(X_train)\n",
        "X_test_scaled = preprocessing.MinMaxScaler().fit_transform(X_test)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHLji_-5FCRl",
        "outputId": "265614b3-ea62-4c2d-a555-9f02b0b7207c"
      },
      "source": [
        "# Balance the training data using SMOTE Tomek\n",
        "X_smt, y_smt = SMOTETomek(random_state=1).fit_sample(X_train_scaled, y_train.squeeze())\n",
        "# X_smt, y_smt = SMOTETomek(random_state=1).fit_sample(X_train, y_train.squeeze())    #use this line, if skipping the scaling step"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5-mG65N_orM"
      },
      "source": [
        "#List the classifiers to be compared\n",
        "names = [\"Logistic_Regression\", \"Decision_Tree\",\"Nearest_Neighbours\", \"QDA\", \"Naive_Bayes\", \"Random_Forest\", \"AdaBoost\", \"GradientBoost\"]  \n",
        "\n",
        "clfs = [\n",
        "    LogisticRegression(random_state=1, C= 50, penalty= 'l1', solver= 'liblinear'),\n",
        "    DecisionTreeClassifier(max_depth=5),              #set max_depth \n",
        "    KNeighborsClassifier(),                           #n_neighbors=5 \n",
        "    QuadraticDiscriminantAnalysis(),\n",
        "    GaussianNB(),\n",
        "    RandomForestClassifier(max_depth=5, n_estimators=100),\n",
        "    AdaBoostClassifier(n_estimators=100), \n",
        "    GradientBoostingClassifier(n_estimators=100, learning_rate=1.0),           \n",
        "    ]"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BP9ITDEi_wkX"
      },
      "source": [
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "\n",
        "for name, clf in zip(names, clfs):\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracies.append(accuracy)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    precisions.append(precision)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    recalls.append(recall)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "PuidISqGjK-O",
        "outputId": "56f3d36b-5b5f-4ad2-ae1a-a035c49e3f24"
      },
      "source": [
        "#Precision= TP/(TP+FP), Recall= TP/(TP+FN)\n",
        "scores_df = pd.DataFrame()\n",
        "scores_df['Algorithm'] = names\n",
        "scores_df['Accuracy'] = accuracies\n",
        "scores_df['Precision'] = precisions\n",
        "scores_df['Recall'] = recalls\n",
        "scores_df"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Algorithm</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic_Regression</td>\n",
              "      <td>0.813267</td>\n",
              "      <td>0.709845</td>\n",
              "      <td>0.250305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Decision_Tree</td>\n",
              "      <td>0.818473</td>\n",
              "      <td>0.659864</td>\n",
              "      <td>0.354446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Nearest_Neighbours</td>\n",
              "      <td>0.757742</td>\n",
              "      <td>0.385733</td>\n",
              "      <td>0.177832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>QDA</td>\n",
              "      <td>0.618793</td>\n",
              "      <td>0.334424</td>\n",
              "      <td>0.746650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Naive_Bayes</td>\n",
              "      <td>0.391484</td>\n",
              "      <td>0.247533</td>\n",
              "      <td>0.870889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Random_Forest</td>\n",
              "      <td>0.812600</td>\n",
              "      <td>0.670000</td>\n",
              "      <td>0.285627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>0.815136</td>\n",
              "      <td>0.653892</td>\n",
              "      <td>0.332521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>GradientBoost</td>\n",
              "      <td>0.804058</td>\n",
              "      <td>0.582857</td>\n",
              "      <td>0.372716</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Algorithm  Accuracy  Precision    Recall\n",
              "0  Logistic_Regression  0.813267   0.709845  0.250305\n",
              "1        Decision_Tree  0.818473   0.659864  0.354446\n",
              "2   Nearest_Neighbours  0.757742   0.385733  0.177832\n",
              "3                  QDA  0.618793   0.334424  0.746650\n",
              "4          Naive_Bayes  0.391484   0.247533  0.870889\n",
              "5        Random_Forest  0.812600   0.670000  0.285627\n",
              "6             AdaBoost  0.815136   0.653892  0.332521\n",
              "7        GradientBoost  0.804058   0.582857  0.372716"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLaAw4BXwuhx"
      },
      "source": [
        "Some notes:\n",
        "\n",
        "* Scaling inputs between 0 and 1 did not affect the performance of the models much.\n",
        "* Can see the trade-off between precision and recall in this algorithms: when precision is high recall suffers, and vice versa."
      ]
    }
  ]
}